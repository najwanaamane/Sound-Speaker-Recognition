{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e8cb53b",
   "metadata": {},
   "source": [
    "# Importing necassary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62009450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io.wavfile\n",
    "import numpy as np\n",
    "from python_speech_features import mfcc\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27db478e",
   "metadata": {},
   "source": [
    "# Defining the function that reads the audios from a given path using scipy and returns 3 lists : audios, freqs, filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "045041e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_audios(path):\n",
    "    audios = []\n",
    "    freqs = []\n",
    "    filepaths = []\n",
    "    #walking through the directory that contains the dataset and reading each file that has the .wav extension\n",
    "    for dp, dn, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.wav'):\n",
    "                filepath = os.path.join(dp, filename)\n",
    "                filepaths.append(filepath)\n",
    "                with open(filepath, \"rb\") as f:\n",
    "                    # load the audio using scipy\n",
    "                    freq, data = scipy.io.wavfile.read(f, mmap=False)\n",
    "                    # append the data and frequency to the respective lists\n",
    "                    audios.append(data)\n",
    "                    freqs.append(freq)\n",
    "    return audios, freqs, filepaths\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4a8d53",
   "metadata": {},
   "source": [
    "# Defining the function that extracts the mfcc features then removes the frames of silence finally it saves the mffc features into a .txt file according to gender \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9d51d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractMfccs_RemoveSilence_saveMfccs(audio, freq, filepath, directory):\n",
    "\n",
    "    \n",
    "    mfcc_features = mfcc(audio, freq, winlen=0.025, winstep=0.01, numcep=13, nfilt=26, nfft=3000, lowfreq=0,\n",
    "                         highfreq=None, preemph=0.97, ceplifter=22, appendEnergy=False)\n",
    "\n",
    "    energy = np.sum(mfcc_features ** 2, axis=1)\n",
    "    threshold = np.mean(energy) * 0.4\n",
    "    voiced_indices = np.where(energy > threshold)[0]\n",
    "    mfccs_voiced = mfcc_features[voiced_indices, :]\n",
    "\n",
    "    print(f\"MFCCs before removing silence: {mfcc_features.shape}\")\n",
    "    print(f\"MFCCs after removing silence: {mfccs_voiced.shape}\")\n",
    "\n",
    "    gender = None\n",
    "    if 'H' in filepath:\n",
    "        gender = 'H'\n",
    "    elif 'F' in filepath:\n",
    "        gender = 'F'\n",
    "\n",
    "    if gender is not None:\n",
    "        gender_dir = os.path.join(directory, gender)\n",
    "        if not os.path.exists(gender_dir):\n",
    "            os.makedirs(gender_dir)\n",
    "        mfcc_file = os.path.join(gender_dir, os.path.splitext(os.path.basename(filepath))[0] + \".mfcc\")\n",
    "        np.savetxt(mfcc_file, mfccs_voiced, delimiter=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936e2c89",
   "metadata": {},
   "source": [
    "# Defining the function that trains a GMM model and than save it as a pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6d31a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm(parentDir,  n_components):\n",
    "\n",
    "    # Loop over the two folders \"H\" and \"F\"\n",
    "    for folder in ['H', 'F']:\n",
    "        # Get the list of files in the folder\n",
    "        folder_path = os.path.join(parentDir, folder)\n",
    "         # Get the list of files in the folder\n",
    "        files = os.listdir(folder_path)\n",
    "\n",
    "        # Loop over the files in the folder\n",
    "        for file in files:\n",
    "            # Load the MFCC features from the file\n",
    "            mfcc_features =np.loadtxt(os.path.join(folder_path, file), delimiter = ',')\n",
    "    \n",
    "\n",
    "            # Create a GMM object\n",
    "            gmm = GaussianMixture(n_components=n_components)\n",
    "\n",
    "            # Fit the GMM to the MFCC features\n",
    "            gmm.fit(mfcc_features)\n",
    "\n",
    "            # Save the trained GMM to a file with a name of Hi.n_components.gmm\n",
    "            gmm_file_name = os.path.splitext(file)[0] + '.' + str(n_components) + '.gmm'\n",
    "            gmm_file_path = os.path.join('GMM', gmm_file_name)\n",
    "            with open(gmm_file_path, 'wb') as f:\n",
    "                pickle.dump(gmm, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3f6cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r'Dataset_1\\Train'\n",
    "output_dir = r'MFCC\\Train'\n",
    "\n",
    "\n",
    "audios, freqs, filepaths = read_audios(train_dir)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3dad5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCCs before removing silence: (5999, 13)\n",
      "MFCCs after removing silence: (5315, 13)\n",
      "MFCCs before removing silence: (5999, 13)\n",
      "MFCCs after removing silence: (5645, 13)\n",
      "MFCCs before removing silence: (5999, 13)\n",
      "MFCCs after removing silence: (5599, 13)\n",
      "MFCCs before removing silence: (5067, 13)\n",
      "MFCCs after removing silence: (4988, 13)\n",
      "MFCCs before removing silence: (5999, 13)\n",
      "MFCCs after removing silence: (5671, 13)\n",
      "MFCCs before removing silence: (6999, 13)\n",
      "MFCCs after removing silence: (6577, 13)\n",
      "MFCCs before removing silence: (999, 13)\n",
      "MFCCs after removing silence: (935, 13)\n",
      "MFCCs before removing silence: (5999, 13)\n",
      "MFCCs after removing silence: (5060, 13)\n",
      "MFCCs before removing silence: (5999, 13)\n",
      "MFCCs after removing silence: (4490, 13)\n",
      "MFCCs before removing silence: (5177, 13)\n",
      "MFCCs after removing silence: (4306, 13)\n",
      "MFCCs before removing silence: (5877, 13)\n",
      "MFCCs after removing silence: (4853, 13)\n",
      "MFCCs before removing silence: (5999, 13)\n",
      "MFCCs after removing silence: (5735, 13)\n"
     ]
    }
   ],
   "source": [
    "for audio, freq, filepath in zip(audios, freqs, filepaths):\n",
    "    extractMfccs_RemoveSilence_saveMfccs(audio, freq, filepath, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dda54f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_components = [16, 32, 128, 256]\n",
    "for n_component in n_components:\n",
    "    gmm(output_dir,  n_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435d3944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05f38c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
