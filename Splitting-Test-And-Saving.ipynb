{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58de5413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import os\n",
    "import scipy.io.wavfile\n",
    "import numpy as np\n",
    "from python_speech_features import mfcc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f24b000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_audios(path):\n",
    "    audios = []\n",
    "    freqs = []\n",
    "    filepaths = []\n",
    "    #walking through the directory that contains the dataset and reading each file that has the .wav extension\n",
    "    for dp, dn, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.wav'):\n",
    "                filepath = os.path.join(dp, filename)\n",
    "                filepaths.append(filepath)\n",
    "                with open(filepath, \"rb\") as f:\n",
    "                    # load the audio using scipy\n",
    "                    freq, data = scipy.io.wavfile.read(f, mmap=False)\n",
    "                    # append the data and frequency to the respective lists\n",
    "                    audios.append(data)\n",
    "                    freqs.append(freq)\n",
    "    return audios, freqs, filepaths\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63c9b96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "import os\n",
    "import scipy.io.wavfile\n",
    "import numpy as np\n",
    "\n",
    "def read_audios(path):\n",
    "    audios = {}\n",
    "    freqs = {}\n",
    "    filepaths = []\n",
    "    # Walking through the directory that contains the dataset and reading each file that has the .wav extension\n",
    "    for dp, dn, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.wav'):\n",
    "                filepath = os.path.join(dp, filename)\n",
    "                filepaths.append(filepath)\n",
    "                # Extract the first two characters after \"Ar_\"\n",
    "                prefix = filename.split(\"_\")[1][:2]\n",
    "                if prefix not in audios:\n",
    "                    audios[prefix] = []\n",
    "                    freqs[prefix] = None\n",
    "                with open(filepath, \"rb\") as f:\n",
    "                    # Load the audio using scipy\n",
    "                    freq, data = scipy.io.wavfile.read(f, mmap=False)\n",
    "                    # Store the audio data and frequency\n",
    "                    if freqs[prefix] is None:\n",
    "                        freqs[prefix] = freq\n",
    "                    audios[prefix].append(data)\n",
    "    return audios, freqs\n",
    "\"\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e864d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "def concatenate_and_save_audio(audios, freqs, output_dir):\n",
    "    for prefix, audio_list in audios.items():\n",
    "        # Concatenate audio data\n",
    "        concatenated_audio = np.concatenate(audio_list)\n",
    "        # Generate output filepath\n",
    "        output_filename = f\"{prefix}.wav\"\n",
    "        output_filepath = os.path.join(output_dir, output_filename)\n",
    "        # Save concatenated audio as WAV file\n",
    "        scipy.io.wavfile.write(output_filepath, freqs[prefix], concatenated_audio)\n",
    "\n",
    "# Define input and output directories\n",
    "input_train_dir = \"Dataset/Train\"\n",
    "input_test_dir = \"Dataset/Test\"\n",
    "output_train_dir = \"Dataset_1/Train\"\n",
    "output_test_dir = \"Dataset_1/Test\"\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs(output_train_dir, exist_ok=True)\n",
    "os.makedirs(output_test_dir, exist_ok=True)\n",
    "\n",
    "# Read audio files from the input directories\n",
    "train_audios, train_freqs = read_audios(input_train_dir)\n",
    "test_audios, test_freqs = read_audios(input_test_dir)\n",
    "\n",
    "# Concatenate and save audio files for training set\n",
    "concatenate_and_save_audio(train_audios, train_freqs, output_train_dir)\n",
    "\n",
    "# Concatenate and save audio files for test set\n",
    "concatenate_and_save_audio(test_audios, test_freqs, output_test_dir)\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e90440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extractMfccs_RemoveSilence_saveMfccs(audio, freq, filepath, directory):\n",
    "\n",
    "    \n",
    "    mfcc_features = mfcc(audio, freq, winlen=0.025, winstep=0.01, numcep=13, nfilt=26, nfft=3000, lowfreq=0,\n",
    "                         highfreq=None, preemph=0.97, ceplifter=22, appendEnergy=False)\n",
    "\n",
    "    energy = np.sum(mfcc_features ** 2, axis=1)\n",
    "    threshold = np.mean(energy) * 0.4\n",
    "    voiced_indices = np.where(energy > threshold)[0]\n",
    "    mfccs_voiced = mfcc_features[voiced_indices, :]\n",
    "\n",
    "    print(f\"MFCCs before removing silence: {mfcc_features.shape}\")\n",
    "    print(f\"MFCCs after removing silence: {mfccs_voiced.shape}\")\n",
    "\n",
    "    gender = None\n",
    "    if 'H' in filepath:\n",
    "        gender = 'H'\n",
    "    elif 'F' in filepath:\n",
    "        gender = 'F'\n",
    "\n",
    "    if gender is not None:\n",
    "        gender_dir = os.path.join(directory, gender)\n",
    "        if not os.path.exists(gender_dir):\n",
    "            os.makedirs(gender_dir)\n",
    "        mfcc_file = os.path.join(gender_dir, os.path.splitext(os.path.basename(filepath))[0] + \".mfcc\")\n",
    "        np.savetxt(mfcc_file, mfccs_voiced, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b1928be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio_test(test_mfccs, segment_length_sec):\n",
    "\n",
    "    # Compute the number of frames per segment\n",
    "    frames_per_sec = 100  # Assuming 100 frames per second\n",
    "    frames_per_segment = int(segment_length_sec * frames_per_sec)\n",
    "\n",
    "    # Split the test audio into segments\n",
    "    num_segments = math.ceil(len(test_mfccs) / frames_per_segment)\n",
    "    test_segments = []\n",
    "    for i in range(num_segments):\n",
    "        start_frame = i * frames_per_segment\n",
    "        end_frame = min(start_frame + frames_per_segment, len(test_mfccs))\n",
    "        segment = test_mfccs[start_frame:end_frame]\n",
    "        test_segments.append(segment)\n",
    "\n",
    "    return test_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fa3d6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCCs before removing silence: (5999, 13)\n",
      "MFCCs after removing silence: (5646, 13)\n",
      "MFCCs before removing silence: (5999, 13)\n",
      "MFCCs after removing silence: (5596, 13)\n",
      "MFCCs before removing silence: (5999, 13)\n",
      "MFCCs after removing silence: (5520, 13)\n",
      "MFCCs before removing silence: (5999, 13)\n",
      "MFCCs after removing silence: (5902, 13)\n",
      "MFCCs before removing silence: (5999, 13)\n",
      "MFCCs after removing silence: (5692, 13)\n",
      "MFCCs before removing silence: (5999, 13)\n",
      "MFCCs after removing silence: (5633, 13)\n",
      "MFCCs before removing silence: (516, 13)\n",
      "MFCCs after removing silence: (497, 13)\n",
      "MFCCs before removing silence: (5999, 13)\n",
      "MFCCs after removing silence: (5120, 13)\n",
      "MFCCs before removing silence: (5999, 13)\n",
      "MFCCs after removing silence: (4739, 13)\n",
      "MFCCs before removing silence: (5999, 13)\n",
      "MFCCs after removing silence: (4774, 13)\n",
      "MFCCs before removing silence: (5999, 13)\n",
      "MFCCs after removing silence: (4897, 13)\n",
      "MFCCs before removing silence: (5999, 13)\n",
      "MFCCs after removing silence: (5473, 13)\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the parent directory where the \"H\" and \"F\" folders are located\n",
    "test_dir = r'Dataset_1\\Test'\n",
    "output_dir = r'MFCC\\Test'\n",
    "\n",
    "audios, freqs, filepaths = read_audios(test_dir)\n",
    "for audio, freq, filepath in zip(audios, freqs, filepaths):\n",
    "    extractMfccs_RemoveSilence_saveMfccs(audio, freq, filepath, output_dir)\n",
    "            \n",
    "\n",
    "        \n",
    "parent_dir = r'MFCC\\Test-segments'\n",
    "durations = [3,10,15,30]\n",
    "# Loop over the two folders \"H\" and \"F\"\n",
    "for folder in ['H', 'F']:\n",
    "    # Get the path to the folder\n",
    "    folder_path = os.path.join(output_dir, folder)\n",
    "    \n",
    "    # Get the list of files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    # Loop over the files in the folder\n",
    "    for file in files:\n",
    "        # Load the MFCC features from the file\n",
    "        test = np.loadtxt(os.path.join(folder_path, file), delimiter=',')\n",
    "        \n",
    "        # Loop over the segment durations\n",
    "        for duration in durations:\n",
    "            # Split the audio into segments of the current duration\n",
    "            test_segments = split_audio_test(test, duration)\n",
    "            \n",
    "            # Get the name of the MFCC file without the extension\n",
    "            mfcc_file_name = os.path.splitext(file)[0]\n",
    "            \n",
    "            # Loop over the segments and save each segment to a file\n",
    "            for i, segment in enumerate(test_segments):\n",
    "                # Define the name of the file\n",
    "                segment_file_name = mfcc_file_name + '.{}.{}.mfcc'.format(duration, i+1)\n",
    "                # Define the path to the file\n",
    "                segment_file_path = os.path.join(parent_dir, str(duration), folder, segment_file_name)\n",
    "                # Save the segment to the file\n",
    "                np.savetxt(segment_file_path, segment, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de55b56d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
